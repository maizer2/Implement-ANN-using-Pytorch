{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28997a1c0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = torch.rand(28, 28, device=device)\n",
    "\n",
    "# resize 3D -> 2D\n",
    "# X.resize()\n",
    "\n",
    "plt.imshow(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "applies a linear transformation\n",
    "\n",
    "$y=xA^{T}+b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __init__(self, a, b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        print(\"Class A is be generate\")\n",
    "\n",
    "class B(A):\n",
    "    def __init__(self):\n",
    "        super(B, self).__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/maizer/1. Dev/3. Git/GitHub/python/Implement-ANN-using-Pytorch/1. Tutorial/1. Basic_torch/LEARN-THE-BASICS/4. Build Model/Build Model.ipynb 셀 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/maizer/1.%20Dev/3.%20Git/GitHub/python/Implement-ANN-using-Pytorch/1.%20Tutorial/1.%20Basic_torch/LEARN-THE-BASICS/4.%20Build%20Model/Build%20Model.ipynb#ch0000011?line=0'>1</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mTNN\u001b[39;00m(nn\u001b[39m.\u001b[39mModule, Input, Output, Final):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maizer/1.%20Dev/3.%20Git/GitHub/python/Implement-ANN-using-Pytorch/1.%20Tutorial/1.%20Basic_torch/LEARN-THE-BASICS/4.%20Build%20Model/Build%20Model.ipynb#ch0000011?line=1'>2</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maizer/1.%20Dev/3.%20Git/GitHub/python/Implement-ANN-using-Pytorch/1.%20Tutorial/1.%20Basic_torch/LEARN-THE-BASICS/4.%20Build%20Model/Build%20Model.ipynb#ch0000011?line=2'>3</a>\u001b[0m         \u001b[39msuper\u001b[39m(TNN, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Input' is not defined"
     ]
    }
   ],
   "source": [
    "class TNN(nn.Module):\n",
    "    def __init__(self, Input, Output, Final):\n",
    "        super(TNN, self).__init__()\n",
    "\n",
    "        self.I = Input\n",
    "        self.O = Output\n",
    "        self.F = Final\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        # self.linear_relu_stack = nn.Sequential(\n",
    "        #     # 28*28=784 -> 512\n",
    "        #     # nn.Linear(28*28, 512, bias=False),\n",
    "        #     nn.Linear(self.I*self.I, self.O, bias=False),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(self.O, self.O, bias=False),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(self.O, self.F, bias=False)\n",
    "        # )\n",
    "        self.linear1 = nn.Linear(self.I * self.I, self.O, bias=False)\n",
    "        self.linear2 = nn.Linear(self.O, self.O, bias=False)\n",
    "        self.linear3 = nn.Linear(self.O, self.F, bias=False)\n",
    "        self.ReLU = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(f\"input image size : {x.size()}\")\n",
    "        x = self.flatten(x)\n",
    "        print(f\"flatten image size : {x.size()}\")\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        print(f\"logits size : {logits.size()}\")\n",
    "        print(f\"logits : {logits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input image size : torch.Size([28, 28])\n",
      "\n",
      "flatten image size : torch.Size([28, 28])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (28x28 and 784x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/maizer/1. Dev/3. Git/GitHub/python/Implement-ANN-using-Pytorch/1. Tutorial/1. Basic_torch/LEARN-THE-BASICS/4. Build Model/Build Model.ipynb 셀 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/maizer/1.%20Dev/3.%20Git/GitHub/python/Implement-ANN-using-Pytorch/1.%20Tutorial/1.%20Basic_torch/LEARN-THE-BASICS/4.%20Build%20Model/Build%20Model.ipynb#ch0000016?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m TNN()\u001b[39m.\u001b[39;49mto(device)(X)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/maizer/1. Dev/3. Git/GitHub/python/Implement-ANN-using-Pytorch/1. Tutorial/1. Basic_torch/LEARN-THE-BASICS/4. Build Model/Build Model.ipynb 셀 9\u001b[0m in \u001b[0;36mTNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maizer/1.%20Dev/3.%20Git/GitHub/python/Implement-ANN-using-Pytorch/1.%20Tutorial/1.%20Basic_torch/LEARN-THE-BASICS/4.%20Build%20Model/Build%20Model.ipynb#ch0000016?line=13'>14</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflatten(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maizer/1.%20Dev/3.%20Git/GitHub/python/Implement-ANN-using-Pytorch/1.%20Tutorial/1.%20Basic_torch/LEARN-THE-BASICS/4.%20Build%20Model/Build%20Model.ipynb#ch0000016?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mflatten image size : \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39msize()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/maizer/1.%20Dev/3.%20Git/GitHub/python/Implement-ANN-using-Pytorch/1.%20Tutorial/1.%20Basic_torch/LEARN-THE-BASICS/4.%20Build%20Model/Build%20Model.ipynb#ch0000016?line=15'>16</a>\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear_relu_stack(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maizer/1.%20Dev/3.%20Git/GitHub/python/Implement-ANN-using-Pytorch/1.%20Tutorial/1.%20Basic_torch/LEARN-THE-BASICS/4.%20Build%20Model/Build%20Model.ipynb#ch0000016?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlogits size : \u001b[39m\u001b[39m{\u001b[39;00mlogits\u001b[39m.\u001b[39msize()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maizer/1.%20Dev/3.%20Git/GitHub/python/Implement-ANN-using-Pytorch/1.%20Tutorial/1.%20Basic_torch/LEARN-THE-BASICS/4.%20Build%20Model/Build%20Model.ipynb#ch0000016?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlogits : \u001b[39m\u001b[39m{\u001b[39;00mlogits\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (28x28 and 784x512)"
     ]
    }
   ],
   "source": [
    "model = TNN().to(device)(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input image ndim : 2\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/maizer/1. Dev/3. Git/GitHub/python/Implement-ANN-using-Pytorch/1. Tutorial/1. Basic_torch/LEARN-THE-BASICS/4. Build Model/Build Model.ipynb 셀 8\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maizer/1.%20Dev/3.%20Git/GitHub/python/Implement-ANN-using-Pytorch/1.%20Tutorial/1.%20Basic_torch/LEARN-THE-BASICS/4.%20Build%20Model/Build%20Model.ipynb#ch0000005?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m TNN()\u001b[39m.\u001b[39mto(device)(X)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maizer/1.%20Dev/3.%20Git/GitHub/python/Implement-ANN-using-Pytorch/1.%20Tutorial/1.%20Basic_torch/LEARN-THE-BASICS/4.%20Build%20Model/Build%20Model.ipynb#ch0000005?line=1'>2</a>\u001b[0m X \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(\u001b[39m1\u001b[39m, \u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m, device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/maizer/1.%20Dev/3.%20Git/GitHub/python/Implement-ANN-using-Pytorch/1.%20Tutorial/1.%20Basic_torch/LEARN-THE-BASICS/4.%20Build%20Model/Build%20Model.ipynb#ch0000005?line=2'>3</a>\u001b[0m logits \u001b[39m=\u001b[39m model(X)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maizer/1.%20Dev/3.%20Git/GitHub/python/Implement-ANN-using-Pytorch/1.%20Tutorial/1.%20Basic_torch/LEARN-THE-BASICS/4.%20Build%20Model/Build%20Model.ipynb#ch0000005?line=4'>5</a>\u001b[0m \u001b[39m# pred_probab = nn.Softmax(dim=1)(logits)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maizer/1.%20Dev/3.%20Git/GitHub/python/Implement-ANN-using-Pytorch/1.%20Tutorial/1.%20Basic_torch/LEARN-THE-BASICS/4.%20Build%20Model/Build%20Model.ipynb#ch0000005?line=5'>6</a>\u001b[0m pred_probab \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSoftmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "\n",
    "# pred_probab = nn.Softmax(dim=1)(logits)\n",
    "pred_probab = nn.Softmax(dim=1)\n",
    "pred_probab = pred_probab(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8e0e1919a95824482f7c7ed5b9775f8717706ba4fd6cb589a6d66ba4fe99650"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
