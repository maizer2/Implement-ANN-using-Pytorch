{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x289503d30>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = torch.rand(28, 28, device=device)\n",
    "\n",
    "# resize 3D -> 2D\n",
    "# X.resize()\n",
    "\n",
    "plt.imshow(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "applies a linear transformation\n",
    "\n",
    "$y=xA^{T}+b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TNN(nn.Module, Input, Output, Final):\n",
    "    def __init__(self):\n",
    "        super(TNN, self).__init__()\n",
    "\n",
    "        self.I = Input\n",
    "        self.O = Output\n",
    "        self.F = Final\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        # self.linear_relu_stack = nn.Sequential(\n",
    "        #     # 28*28=784 -> 512\n",
    "        #     # nn.Linear(28*28, 512, bias=False),\n",
    "        #     nn.Linear(self.I*self.I, self.O, bias=False),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(self.O, self.O, bias=False),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(self.O, self.F, bias=False)\n",
    "        # )\n",
    "        self.linear1 = nn.Linear(self.I * self.I, self.O, bias=False)\n",
    "        self.\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(f\"input image size : {x.size()}\")\n",
    "        print(f\"\")\n",
    "        x = self.flatten(x)\n",
    "        print(f\"flatten image size : {x.size()}\")\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        print(f\"logits size : {logits.size()}\")\n",
    "        print(f\"logits : {logits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input image size : torch.Size([28, 28])\n",
      "\n",
      "flatten image size : torch.Size([28, 28])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (28x28 and 784x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/maizer/1. Dev/3. Git/GitHub/python/Implement-ANN-using-Pytorch/1. Tutorial/1. Basic_torch/LEARN-THE-BASICS/4. Build Model/Build Model.ipynb 셀 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/maizer/1.%20Dev/3.%20Git/GitHub/python/Implement-ANN-using-Pytorch/1.%20Tutorial/1.%20Basic_torch/LEARN-THE-BASICS/4.%20Build%20Model/Build%20Model.ipynb#ch0000016?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m TNN()\u001b[39m.\u001b[39;49mto(device)(X)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/maizer/1. Dev/3. Git/GitHub/python/Implement-ANN-using-Pytorch/1. Tutorial/1. Basic_torch/LEARN-THE-BASICS/4. Build Model/Build Model.ipynb 셀 9\u001b[0m in \u001b[0;36mTNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maizer/1.%20Dev/3.%20Git/GitHub/python/Implement-ANN-using-Pytorch/1.%20Tutorial/1.%20Basic_torch/LEARN-THE-BASICS/4.%20Build%20Model/Build%20Model.ipynb#ch0000016?line=13'>14</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflatten(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maizer/1.%20Dev/3.%20Git/GitHub/python/Implement-ANN-using-Pytorch/1.%20Tutorial/1.%20Basic_torch/LEARN-THE-BASICS/4.%20Build%20Model/Build%20Model.ipynb#ch0000016?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mflatten image size : \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39msize()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/maizer/1.%20Dev/3.%20Git/GitHub/python/Implement-ANN-using-Pytorch/1.%20Tutorial/1.%20Basic_torch/LEARN-THE-BASICS/4.%20Build%20Model/Build%20Model.ipynb#ch0000016?line=15'>16</a>\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear_relu_stack(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maizer/1.%20Dev/3.%20Git/GitHub/python/Implement-ANN-using-Pytorch/1.%20Tutorial/1.%20Basic_torch/LEARN-THE-BASICS/4.%20Build%20Model/Build%20Model.ipynb#ch0000016?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlogits size : \u001b[39m\u001b[39m{\u001b[39;00mlogits\u001b[39m.\u001b[39msize()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maizer/1.%20Dev/3.%20Git/GitHub/python/Implement-ANN-using-Pytorch/1.%20Tutorial/1.%20Basic_torch/LEARN-THE-BASICS/4.%20Build%20Model/Build%20Model.ipynb#ch0000016?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlogits : \u001b[39m\u001b[39m{\u001b[39;00mlogits\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (28x28 and 784x512)"
     ]
    }
   ],
   "source": [
    "model = TNN().to(device)(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input image ndim : 2\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/maizer/1. Dev/3. Git/GitHub/python/Implement-ANN-using-Pytorch/1. Tutorial/1. Basic_torch/LEARN-THE-BASICS/4. Build Model/Build Model.ipynb 셀 8\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maizer/1.%20Dev/3.%20Git/GitHub/python/Implement-ANN-using-Pytorch/1.%20Tutorial/1.%20Basic_torch/LEARN-THE-BASICS/4.%20Build%20Model/Build%20Model.ipynb#ch0000005?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m TNN()\u001b[39m.\u001b[39mto(device)(X)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maizer/1.%20Dev/3.%20Git/GitHub/python/Implement-ANN-using-Pytorch/1.%20Tutorial/1.%20Basic_torch/LEARN-THE-BASICS/4.%20Build%20Model/Build%20Model.ipynb#ch0000005?line=1'>2</a>\u001b[0m X \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(\u001b[39m1\u001b[39m, \u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m, device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/maizer/1.%20Dev/3.%20Git/GitHub/python/Implement-ANN-using-Pytorch/1.%20Tutorial/1.%20Basic_torch/LEARN-THE-BASICS/4.%20Build%20Model/Build%20Model.ipynb#ch0000005?line=2'>3</a>\u001b[0m logits \u001b[39m=\u001b[39m model(X)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maizer/1.%20Dev/3.%20Git/GitHub/python/Implement-ANN-using-Pytorch/1.%20Tutorial/1.%20Basic_torch/LEARN-THE-BASICS/4.%20Build%20Model/Build%20Model.ipynb#ch0000005?line=4'>5</a>\u001b[0m \u001b[39m# pred_probab = nn.Softmax(dim=1)(logits)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maizer/1.%20Dev/3.%20Git/GitHub/python/Implement-ANN-using-Pytorch/1.%20Tutorial/1.%20Basic_torch/LEARN-THE-BASICS/4.%20Build%20Model/Build%20Model.ipynb#ch0000005?line=5'>6</a>\u001b[0m pred_probab \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSoftmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "\n",
    "# pred_probab = nn.Softmax(dim=1)(logits)\n",
    "pred_probab = nn.Softmax(dim=1)\n",
    "pred_probab = pred_probab(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8e0e1919a95824482f7c7ed5b9775f8717706ba4fd6cb589a6d66ba4fe99650"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
