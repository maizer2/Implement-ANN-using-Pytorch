{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import json\n",
    "\n",
    "from typing import Dict, Optional, Callable, List, Tuple\n",
    "from glob import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_root(root: str, train: bool) -> str:\n",
    "    if root[-1] != \"/\":\n",
    "        root += \"/\"\n",
    "\n",
    "    if train:\n",
    "        root += \"Training/\"\n",
    "    else:\n",
    "        root += \"Validation/\"\n",
    "\n",
    "    return root \n",
    "\n",
    "def read_json(json_path: str) -> Dict:\n",
    "    path = open(json_path, 'r')\n",
    "    return json.load(path)\n",
    "\n",
    "class FP_and_WI(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        root: str, \n",
    "        train: bool = True, \n",
    "        size: Tuple[int] = (720, 1280),\n",
    "\n",
    "        transform: Optional[Callable] = None\n",
    "        ):\n",
    "\n",
    "        # ../FP_and_WI/\n",
    "        self.root = val_root(root, train)\n",
    "        self.wearing_info = read_json(self.root + \"labels/wearing_info.json\")\n",
    "\n",
    "        self.img_size = size\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.wearing_info)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        #############################################\n",
    "        # Get cloth information that fits the index #\n",
    "        #############################################\n",
    "\n",
    "        wearing_info = self.wearing_info[idx]\n",
    "        \n",
    "        ##########################################\n",
    "        # Split a information using wearing_info #\n",
    "        # 1. Get model_path_info                 #\n",
    "        # 2. Split Keys and Values each variable #\n",
    "        ##########################################\n",
    "\n",
    "        model_path_info = wearing_info['wearing'].split('.')[0]\n",
    "        item_name_info = list(wearing_info.keys())[1:]\n",
    "        item_path_info = list(wearing_info.values())[1:]\n",
    "        \n",
    "        ########################################################\n",
    "        #                      L A B E L                       #\n",
    "        # Get model_info = [model_parse_info, model_pose_info] #\n",
    "        # 1. List of model_parse_info get using model_pat_info #  \n",
    "        # 2. List of model_pose_info get using model_path_info #\n",
    "        # 3. Combine parse and pose to List                    #\n",
    "        ########################################################\n",
    "\n",
    "        model_parse_info = read_json(self.root + f\"labels/Model-Parse_f/{model_path_info}.json\")\n",
    "        model_parse_info = list(model_parse_info.values())[1:-1]\n",
    "        \n",
    "        model_pose_info = read_json(self.root + f\"labels/Model-Pose_f/{model_path_info}.json\")\n",
    "        model_pose_info = list(model_pose_info.values())[1:-1]\n",
    "        \n",
    "        model_info = [model_parse_info, model_pose_info]\n",
    "\n",
    "        #############################################################\n",
    "        # Get item_info = [item_parse_info, item_pose_info]         #\n",
    "        # Using item_path_info but that is more than one value      #\n",
    "        # 1. Loop using item_path_info each value                   #\n",
    "        # 2. Some value is None, and then append None value to list #\n",
    "        # 3. Read each json file and append value to list           #\n",
    "        # 4. Combine parse and pose to List                         #\n",
    "        #############################################################\n",
    "\n",
    "        item_F_parse_info, item_B_parse_info = [], []\n",
    "        item_F_pose_info, item_B_pose_info = [], []\n",
    "\n",
    "        for item in item_path_info:\n",
    "            if item != None:\n",
    "                F_parse_json = read_json(self.root + f\"labels/Item-Parse_f/{item}_F.json\")\n",
    "                item_F_parse_info.append(list(F_parse_json))\n",
    "\n",
    "                B_parse_json = read_json(self.root + f\"labels/Item-Parse_f/{item}_B.json\")\n",
    "                item_B_parse_info.append(list(B_parse_json))\n",
    "\n",
    "                F_pose_json = read_json(self.root + f\"labels/Item-Pose_f/{item}_F.json\")\n",
    "                item_F_pose_info.append(list(F_pose_json))\n",
    "\n",
    "                B_pose_json = read_json(self.root + f\"labels/Item-Pose_f/{item}_B.json\")\n",
    "                item_B_pose_info.append(list(B_pose_json))\n",
    "            else:\n",
    "                item_F_parse_info.append(None)\n",
    "                item_B_parse_info.append(None)\n",
    "\n",
    "                item_F_pose_info.append(None)\n",
    "                item_B_pose_info.append(None)\n",
    "\n",
    "        item_parse_info = [item_F_parse_info, item_B_parse_info]\n",
    "        item_pose_info = [item_F_pose_info, item_B_pose_info]\n",
    "\n",
    "        item_info = [item_parse_info, item_pose_info]\n",
    "        \n",
    "        ########################################\n",
    "        # Get labels = [model_info, item_info] #\n",
    "        ########################################\n",
    "\n",
    "        label = [model_info, item_info]\n",
    "\n",
    "        ######################################################\n",
    "        #                     I M A G E                      #\n",
    "        # Get Model and Item image                           #\n",
    "        # 1. Get Model image                                 #\n",
    "        # 2. Get Item image                                  #\n",
    "        # 3. img = [transform_model_img, transform_item_img] #\n",
    "        ######################################################\n",
    "\n",
    "        ####################\n",
    "        # Get model image  #\n",
    "        # 1. Image.open    #\n",
    "        # *. Image splin   #\n",
    "        # 2. Transform img #\n",
    "        ####################\n",
    "\n",
    "        model_img = Image.open(self.root + f\"images/Model-Image_deid/{model_path_info}.jpg\").convert(\"RGB\")\n",
    "        \n",
    "        ###########################################################################################################\n",
    "        # Some of the images in the data set have a defect that is (1280, 720) size rather than (720, 1280) size. #\n",
    "        # Image spin Using PIL.Image.transpose model                                                              #\n",
    "        ###########################################################################################################\n",
    "\n",
    "        if model_img.size == (1280, 720):\n",
    "            model_img = model_img.transpose(Image.Transpose.ROTATE_270)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            transform_model_img = self.transform(model_img)\n",
    "        \n",
    "        ###################################################\n",
    "        # Get item image                                  #\n",
    "        # Item image is more then one item                #\n",
    "        # Item image has F(ront) and B(ehind)             #\n",
    "        # 1. Loop using item_path_info each value         #\n",
    "        # 2. Image.open                                   #\n",
    "        # 3. Transform img                                #\n",
    "        # 4. Combine each item to list transform_item_img #\n",
    "        ###################################################\n",
    "\n",
    "        transform_item_F_img, transform_item_B_img = [], []\n",
    "\n",
    "        for item in item_path_info:\n",
    "            if item is not None:\n",
    "                item_F_img = Image.open(self.root + f\"images/Item-Image/{item}_F.jpg\")\n",
    "                item_B_img = Image.open(self.root + f\"images/Item-Image/{item}_B.jpg\")\n",
    "                transform_item_F_img.append(self.transform(item_F_img))\n",
    "                transform_item_B_img.append(self.transform(item_B_img))\n",
    "            else:\n",
    "                transform_item_F_img.append(None)\n",
    "                transform_item_B_img.append(None)\n",
    "\n",
    "        transform_item_img = [transform_item_F_img, transform_item_F_img]\n",
    "\n",
    "        ########################################################\n",
    "        # Get item = [transform_model_img, transform_item_img] #\n",
    "        ########################################################\n",
    "\n",
    "        item = [transform_model_img, transform_item_img]\n",
    "\n",
    "        return item, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [126], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtransforms\u001b[39;00m\n\u001b[1;32m      3\u001b[0m train_data \u001b[39m=\u001b[39m FP_and_WI(\n\u001b[1;32m      4\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m/data/DataSet/FP_and_WI/\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     transform\u001b[39m=\u001b[39mtransforms\u001b[39m.\u001b[39mCompose([\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     ])\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m train_data[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_data = FP_and_WI(\n",
    "    \"/data/DataSet/FP_and_WI/\",\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        transforms.Resize((256, 256))\n",
    "    ])\n",
    ")\n",
    "\n",
    "train_data[0][1].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
